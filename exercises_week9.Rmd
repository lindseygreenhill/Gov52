---
title: "exercises_week9"
author: "Lindsey Greenhill"
date: "3/24/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(stargazer)
library(tidyverse)

df <-foreign::read.dta("http://www.stat.columbia.edu/~gelman/arm/examples/risky.behavior/risky_behaviors.dta")

# making variable into integer

df <- df %>%
  mutate(fupacts = as.integer(fupacts))
```


# Question 1

## Part a

```{r}

# DO I NEED TO ADD THE COUPLES THING?

mod_a  <- glm(fupacts ~ women_alone, data = df, family = "poisson")


summary(mod_a)

# look at the deviance residuals. The min and the max should be relatively equal
# in absolute value. If they aren't, it hints at overdispersion.

# look at the deviances:  roughly 240 on 1 degree of freedom. We are way in the
# tail. So much so that we don't have to do the p chisq thing.

ssr <- (df$fupacts - mod_a$fitted.values)^2/sqrt(mod_a$fitted.values)
sum_ssr <- sum(ssr^2)

# k is the number of variables that you add over the mean model
# 1 df. Value is way into the tail, so there is a problem. 

# WHY IS THS WRONG???

over <- 1/(nrow(df) - mod_a$df.null -  mod_a$df.residual)*sum_ssr

```
### Model fit

* The treatment variable appears to be statistically significant

* There is a significant difference between the null deviance and the residual
deviance, indicating that the model is better than the null model

### Overdisperion check

There are a few ways to check for overdispersion. A quick way to check is to
look at the minimum and maximum deviance residuans. If the model is a good fit,
the min and max should be relatively equal in absolute value.

* The minimum deviance residual = -6 while the maximum deviance residual = 27.2.
These two values differ substantially in absolute value and hints at
overdispersion

Another way to check for overdispersion is to perform a chi squared test on the
sum of the squared residuals. If the model is not a good fit, the test statistic
will be in the tail of the distribution.

* The sum of the squared residuals (220045935) is large enough that we know it
will be in the tail of the chi squared distribution, which also hints at
overdispersion.

We can also look at the overdispersion ratio, which is also far into the tail of
the chi squared distribution and also suggests overdispersion

## Part b

In the code below I extend the model to include pre-treatment variables.

```{r}
mod_b <- glm(fupacts ~ women_alone  + sex + couples + bs_hiv + bupacts, data = df,
              family = "poisson")

summary(mod_b)

# look at the deviance residuals. The min and the max should be relatively equal in absolute value. If they aren't, it hints at overdispersion. 


ssr_b <- (df$fupacts - mod_b$fitted.values)^2/sqrt(mod_b$fitted.values)
sum_ssr_b <- sum(ssr_b^2)

# k is the number of variables that you add over the mean model 5 df. Value is
# way into the tail, so there is a problem. So there appears to be
# overdispersion. It is over 3.84 (alpha = .05). It means thatthe  standard
# errors are wrong/not calculated correctly.

over_b <- 1/(nrow(df) - (mod_b$df.null - mod_b$df.residual))*sum_ssr_b
```

### Model fit

* All of the variables appear to be statistically significant

* There is a significant difference between the null deviance and the residual
deviance, indicating that the model is improved from the model in part a

### Overdisperion check

* The minimum and maximum deviance residuals are closer in absolute value than
they were in moda, however, they are differ by 5, hinting at overdispersion

* The sum of the squared residuals (100100674) is far into the tail of the chi
squared distribution, also suggesting overdispersion

* The overdispersion ratio (233334.9) is also far into the tail of the chi
squared distribution, also suggesting overdispersion

## Part c

In the code below I fit an overdispersed Poission model using the glm.nm() function. 

```{r}

#  fitting a negative binomial

mod_c  <- glm.nb(fupacts ~ women_alone  + sex + couples + bs_hiv + bupacts, data = df)

summary(mod_c)

# really changes the  deviance residuals range. the min and max are pretty much equal now (abs value). Sex and couples become not statistically significant. 

ssr_c <- (df$fupacts - mod_c$fitted.values)^2/sqrt(mod_c$fitted.values)
sum_ssr_c <- sum(ssr_c^2)

# k is the number of variables that you add over the mean model
# 5 df. Value is way into the tail, so there is a problem. So there appears to be overdispersion. It is over 3.84 (alpha = .05). It means thatthe  standard errors are wrong/not calculated correctly. 

over_c <- 1/(nrow(df) - (mod_c$df.null - mod_c$df.residual))*sum_ssr_c

```
### Effectiveness of intervention

* The coefficient estimates change from moda/modb to modc, suggesting that the new model may have been an effective intervention

* Two variables that were statistically significant in the previous models are now not statistically significant (sexman and couples), suggesting that this model may have more accurately calculated the standard errors and was thus an effective intervention

* The min and max deviance residuals aare now relatively equal in absolute value, suggesting that the the intervention was effective

## Part d

I have concerns about the IID Arrivals assumption (the assumption that the observations are independent and identially distributed). I would expect the sexual activities of couples are not independent and are highly correlated. Because the data includes responses from both men and women in the same couple, the observations are probably not completely independent. 


# Question 2

```{r include=FALSE}

# need this library to do the regression

library(nnet)
library(sjPlot)

# reading in data

nes <- foreign::read.dta("http://www.stat.columbia.edu/~gelman/arm/examples/nes/nes5200_processed_voters_realideo.dta") %>% 
  filter(year == 2000) %>%
  select(partyid3,age, gender, race, educ1, income, ideo7)

nes_clean <- nes %>%
  drop_na() %>%
  mutate(
    gender = as.numeric(str_sub(gender, 1, 1)) - 1,
    educ1 = as.double(str_sub(educ1, 1, 1)),
    partyid3 = as_factor(str_sub(partyid3, 1, 1)),
    income = as.double(str_sub(income, 1, 1)),
    ideo7 = as.double(str_sub(ideo7, 1, 1)),
    race = as_factor(str_sub(race, 1, 1))
  ) %>%
  mutate(partyid3 = if_else(partyid3 == 3, "R",
                            if_else(partyid3 == 2, "I", "D"))) %>%
  mutate(race = case_when(race == 1 ~ "white",
                          race == 2 ~ "black",
                          race == 3 ~ "asian",
                          race == 4 ~ "native_american",
                          race == 5 ~ "hispanic"))

nes_clean_simple <- nes_clean %>%
 select(-race, -gender)
```

## Part a

```{r}

# using the method from class

mod_2 <- multinom(partyid3 ~ age + educ1 + income + ideo7,
                  data = nes_clean_simple)
summary(mod_2)

# alternative way

mod_3 <- polr(factor(partyid3) ~ age + educ1 + income + ideo7, 
              data = nes_clean_simple)

# from book

expected <- function(x, c1.5, c2.5, sigma){
  p1.5 <- invlogit((x-c1.5)/sigma)
  p2.5 <- invlogit((x-c2.5)/sigma)
  return((1*(1-p1.5) + 2*(p.15-p2.5) + 3*p2.5))
}

summary(mod_3)

plot_model(mod_3,
           type = "est",
           title = "Multinomial Model Results")

```

## Part c

Use the model to make predictions about the vote choice for some test cases of interest

```{r}

# this row is someone who is 63, has some college, 34 to 67th percentile income, and is slightly conservative. They are actually a D. 

pred_df <- nes_clean_simple %>%
  slice(1) %>%
  select(-partyid3)

# The model incorrectly predicts this person to be R

predict(mod_3, pred_df)

# case 2. This person is 40, has some college, 34 to 67th percentile income, and is conservative. They are actually a R. 

pred_df_2 <- nes_clean_simple %>%
  slice(2)  %>%
  select(-partyid3)

# The model correctly predicts this person is R

predict(mod_3, pred_df_2)
```




